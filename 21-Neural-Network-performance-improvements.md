- Vanishing Gradient
- Overfitting
  - Dropouts - dropout only on training time, not on testing time
    - Convergence will be slow due to dropout
    - loss functions will be affected due to dropout and as a result debugging gradients calculations will be difficult 
  - Early stopping
- Normalization
  - Noramalizing inputs
- Gradient checking and clipping
- Optimizers
- Learning rate and scheduling
- Hyperparameters tuning
